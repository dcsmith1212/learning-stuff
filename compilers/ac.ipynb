{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Peekable():\n",
    "    def __init__(self, iterable):\n",
    "        self.index = 0\n",
    "        self.iterable = iterable\n",
    "        self.length = len(iterable)\n",
    "\n",
    "    def eof(self):\n",
    "        return self.index >= self.length\n",
    "    \n",
    "    def peek(self):\n",
    "        return self.iterable[self.index] if not self.eof() else None\n",
    "        \n",
    "    def advance(self):\n",
    "        thing = self.peek()\n",
    "        self.index += 1\n",
    "        return thing\n",
    "    \n",
    "    def get_iterable(self):\n",
    "        return self.iterable[self.index:] if not self.eof() else None\n",
    "\n",
    "    def to_string(self):\n",
    "        return str(self.get_iterable())\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token():\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.type = kwargs.pop('type', None)\n",
    "        self.val  = kwargs.pop('val',  None)\n",
    "    \n",
    "    def to_string(self):\n",
    "        infoList = []\n",
    "        if self.type:\n",
    "            infoList.append(f'type = {self.type}')\n",
    "        if self.val:\n",
    "            infoList.append(f'val = {self.val}')\n",
    "        infoString = ', '.join(infoList)\n",
    "        return f'Token({infoString})'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scanner():\n",
    "    digits = ['0','1','2','3','4','5','6','7','8','9']\n",
    "    letters = ['a','b','c','d','e','g','h','j','k','l','m','o','q','r','s','t','u','v','w','x','y','z']\n",
    "    keywords = ['f','i','p']\n",
    "    whitespace = [' ','\\n','\\t']\n",
    "\n",
    "    def __init__(self, program):\n",
    "        self.program = Peekable(program)\n",
    "\n",
    "    def scan(self):\n",
    "        tokens = []\n",
    "        while not self.program.eof():\n",
    "            tokens.append(self.scan_next_character())\n",
    "        return tokens\n",
    "\n",
    "    def scan_next_character(self):\n",
    "        while self.program.peek() in self.whitespace:\n",
    "            self.program.advance()\n",
    "        \n",
    "        if self.program.eof():\n",
    "            return Token(type='$')\n",
    "        \n",
    "        if self.program.peek() in self.digits:\n",
    "            return self.scan_digits()\n",
    "        \n",
    "        ch = self.program.advance()\n",
    "        if ch in self.letters:\n",
    "            return Token(type='id', val=ch)\n",
    "        \n",
    "        match ch:\n",
    "            case 'f':\n",
    "                return Token(type='floatdcl')\n",
    "            case 'i':\n",
    "                return Token(type='intdcl')\n",
    "            case 'p':\n",
    "                return Token(type='print')\n",
    "            case '=':\n",
    "                return Token(type='assign')\n",
    "            case '+':\n",
    "                return Token(type='plus')\n",
    "            case '-':\n",
    "                return Token(type='minus')\n",
    "            case _:\n",
    "                self.lexical_error()\n",
    "\n",
    "    def scan_digits(self):\n",
    "        tok = Token(val='')\n",
    "        while self.program.peek() in self.digits:\n",
    "            nextThing = self.program.advance()\n",
    "            tok.val += nextThing\n",
    "        \n",
    "        if self.program.peek() != '.':\n",
    "            tok.type = 'inum'\n",
    "        else:\n",
    "            tok.type = 'fnum'\n",
    "            tok.val += self.program.advance()\n",
    "            while self.program.peek() in self.digits:\n",
    "                tok.val += self.program.advance()\n",
    "        \n",
    "        return tok\n",
    "    \n",
    "    def lexical_error(self):\n",
    "        sys.exit('Lexical error!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, type, val=None):\n",
    "        self.type = type\n",
    "        self.val = val\n",
    "        self.children = []\n",
    "        self.id = None\n",
    "    \n",
    "    def add_child(self, node):\n",
    "        self.children.append(node)\n",
    "\n",
    "    def add_parent(self, node):\n",
    "        self.parent = node\n",
    "        self.parent.add_child(self)\n",
    "     \n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "\n",
    "    def get_type(self):\n",
    "        return self.type\n",
    "    \n",
    "    def get_val(self):\n",
    "        return self.val\n",
    "\n",
    "    def get_child(self, index):\n",
    "        children = self.get_children()\n",
    "        return children[index] if index < self.num_children() else None\n",
    "\n",
    "    def get_children(self):\n",
    "        return self.children\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.num_children() == 0\n",
    "    \n",
    "    def num_children(self):\n",
    "        return len(self.children)\n",
    "\n",
    "    def set_id(self, id):\n",
    "        self.id = id\n",
    "\n",
    "    def to_string(self):\n",
    "        return f'Node({self.get_type()})'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.to_string()\n",
    "\n",
    "class Tree():\n",
    "    def __init__(self):\n",
    "        self.nodes = {}\n",
    "        self.root = None\n",
    "\n",
    "    def add_node(self, node, parent=None):\n",
    "        id = self.num_nodes()\n",
    "\n",
    "        if parent:\n",
    "            parentId = parent.get_id()\n",
    "            if parentId not in self.nodes:\n",
    "                print('You provided a parent node that is not in the graph, not adding this node.')\n",
    "                return\n",
    "        \n",
    "            node.add_parent(parent)\n",
    "        \n",
    "        node.set_id(id)\n",
    "        self.nodes[id] = node\n",
    "\n",
    "        # By convention, the first node added will be the root\n",
    "        if id == 0:\n",
    "            self.root = node\n",
    "\n",
    "    def get_root(self):\n",
    "        return self.root\n",
    "\n",
    "    def num_nodes(self):\n",
    "        return len(self.nodes)\n",
    "\n",
    "    def render_tree(self, node=None, preamble=''):\n",
    "        if not node:\n",
    "            node = self.root\n",
    "\n",
    "        string = preamble + node.get_type() \n",
    "        if node.get_val():\n",
    "            string += f' ({node.get_val()})'\n",
    "        string += '\\n'\n",
    "\n",
    "        children = node.get_children()\n",
    "        for i, child in enumerate(children):\n",
    "            nextPreamble = preamble\n",
    "            nextPreamble = nextPreamble.replace('├','│').replace('─',' ').replace('└',' ')\n",
    "            nextPreamble += '└── ' if i == len(children) - 1 else '├── '\n",
    "            string += self.render_tree(child, nextPreamble)\n",
    "        return string\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.render_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser():\n",
    "    def __init__(self, tokens):\n",
    "        # We don't need to token 'val' field to check syntax\n",
    "        self.tokens = Peekable(tokens)\n",
    "        self.verbose = True\n",
    "        self.depth = 0\n",
    "        self.callStack = []\n",
    "        self.parseTree = Tree()\n",
    "        self.ast = Tree()\n",
    "\n",
    "    def parse(self):\n",
    "        self.prog()\n",
    "        self.convert_parse_tree_to_ast()\n",
    "        print('Your program is syntactically valid!')\n",
    "\n",
    "    def prog(self):\n",
    "        self.append_to_call_stack('prog')\n",
    "        \n",
    "        node = Node('Prog')\n",
    "        self.parseTree.add_node(node)\n",
    "\n",
    "        if self.tokens.peek().type in ['floatdcl', 'intdcl', 'id', 'print', '$']:\n",
    "            self.dcls(node)\n",
    "            self.stmts(node)\n",
    "\n",
    "            eosNode = Node('$')\n",
    "            self.parseTree.add_node(eosNode, parent=node)\n",
    "        else:\n",
    "            self.syntax_error('prog')\n",
    "    \n",
    "    def dcls(self, parentNode):\n",
    "        self.depth += 1\n",
    "        self.append_to_call_stack('dcls')\n",
    "\n",
    "        node = Node('Dcls')\n",
    "        self.parseTree.add_node(node, parent=parentNode)\n",
    "\n",
    "        if self.tokens.peek().type in ['floatdcl', 'intdcl']:\n",
    "            self.dcl(node)\n",
    "            self.dcls(node)\n",
    "        elif self.tokens.peek().type in ['id', 'print', '$']:\n",
    "            # Do nothing for lambda production, $ is next\n",
    "            lambdaNode = Node('λ')\n",
    "            self.parseTree.add_node(lambdaNode, parent=node)\n",
    "        else:\n",
    "            self.syntax_error('dcls')\n",
    "        self.depth -= 1\n",
    "\n",
    "    def dcl(self, parentNode):\n",
    "        self.depth += 1\n",
    "        self.append_to_call_stack('dcl')\n",
    "\n",
    "        node = Node('Dcl')\n",
    "        self.parseTree.add_node(node, parent=parentNode)\n",
    "\n",
    "        if self.tokens.peek().type == 'floatdcl':\n",
    "            self.match('floatdcl', node)\n",
    "            self.match('id', node)\n",
    "        elif self.tokens.peek().type == 'intdcl':\n",
    "            self.match('intdcl', node)\n",
    "            self.match('id', node)\n",
    "        else:\n",
    "            self.syntax_error('dcl')\n",
    "        self.depth -= 1\n",
    "\n",
    "    def stmts(self, parentNode):\n",
    "        self.depth += 1\n",
    "        self.append_to_call_stack('stmts')\n",
    "\n",
    "        node = Node('Stmts')\n",
    "        self.parseTree.add_node(node, parent=parentNode)\n",
    "\n",
    "        if self.tokens.peek().type in ['id', 'print']:\n",
    "            self.stmt(node)\n",
    "            self.stmts(node)\n",
    "        elif self.tokens.peek().type == '$':\n",
    "            # Do nothing for lambda production, $ is next\n",
    "            lambdaNode = Node('λ')\n",
    "            self.parseTree.add_node(lambdaNode, parent=node)\n",
    "        else:\n",
    "            self.syntax_error('stmts')\n",
    "        self.depth -= 1\n",
    "\n",
    "    def stmt(self, parentNode):\n",
    "        self.depth += 1\n",
    "        self.append_to_call_stack('stmt')\n",
    "\n",
    "        node = Node('Stmt')\n",
    "        self.parseTree.add_node(node, parent=parentNode)\n",
    "\n",
    "        if self.tokens.peek().type == 'id':\n",
    "            self.match('id', node)\n",
    "            self.match('assign', node)\n",
    "            self.val(node)\n",
    "            self.expr(node)\n",
    "        elif self.tokens.peek().type == 'print':\n",
    "            self.match('print', node)\n",
    "            self.match('id', node)\n",
    "        else:\n",
    "            self.syntax_error('stmt')\n",
    "        self.depth -= 1\n",
    "\n",
    "    def expr(self, parentNode):\n",
    "        self.depth += 1\n",
    "        self.append_to_call_stack('expr')\n",
    "\n",
    "        node = Node('Expr')\n",
    "        self.parseTree.add_node(node, parent=parentNode)\n",
    "\n",
    "        if self.tokens.peek().type == 'plus':\n",
    "            self.match('plus', node)\n",
    "            self.val(node)\n",
    "            self.expr(node)\n",
    "        elif self.tokens.peek().type == 'minus':\n",
    "            self.match('minus', node)\n",
    "            self.val(node)\n",
    "            self.expr(node)\n",
    "        elif self.tokens.peek().type in ['id', 'print', '$']:\n",
    "            # Do nothing for lambda production, Stmt or $ is next\n",
    "            lambdaNode = Node('λ')\n",
    "            self.parseTree.add_node(lambdaNode, parent=node)\n",
    "        else:\n",
    "            self.syntax_error('expr')\n",
    "        self.depth -= 1\n",
    "\n",
    "    def val(self, parentNode):\n",
    "        self.depth += 1\n",
    "        self.append_to_call_stack('val')\n",
    "\n",
    "        node = Node('Val')\n",
    "        self.parseTree.add_node(node, parent=parentNode)\n",
    "\n",
    "        if self.tokens.peek().type == 'id':\n",
    "            self.match('id', node)\n",
    "        elif self.tokens.peek().type == 'inum':\n",
    "            self.match('inum', node)\n",
    "        elif self.tokens.peek().type == 'fnum':\n",
    "            self.match('fnum', node)\n",
    "        else:\n",
    "            self.syntax_error('val')\n",
    "        self.depth -= 1\n",
    "\n",
    "    def match(self, compare, parentNode):\n",
    "        self.depth += 1\n",
    "        self.append_to_call_stack('match')\n",
    "\n",
    "        nextToken = self.tokens.peek()\n",
    "        if nextToken.type == compare:\n",
    "            node = Node(compare, val=nextToken.val)\n",
    "            self.parseTree.add_node(node, parent=parentNode)\n",
    "\n",
    "            self.depth -= 1\n",
    "            return self.tokens.advance()\n",
    "        else:\n",
    "            self.syntax_error('match')\n",
    "\n",
    "    def get_ast(self):\n",
    "        return self.ast\n",
    "\n",
    "    def get_parse_tree(self):\n",
    "        return self.parseTree\n",
    "    \n",
    "    def convert_parse_tree_to_ast(self):       \n",
    "        progNode = Node('Program')\n",
    "        self.ast.add_node(progNode)    \n",
    "\n",
    "        def recurse_on_expr(exprNode, prevTermNode, astParentNode):\n",
    "            if exprNode.num_children() == 1 and exprNode.get_child(0).get_type() == 'λ':\n",
    "                self.ast.add_node(prevTermNode, parent=astParentNode)\n",
    "            else:\n",
    "                pluOrMinusNode = exprNode.get_child(0)\n",
    "                self.ast.add_node(pluOrMinusNode, parent=astParentNode)\n",
    "                self.ast.add_node(prevTermNode, parent=pluOrMinusNode)\n",
    "\n",
    "                valNode = exprNode.get_child(1).get_child(0)\n",
    "\n",
    "                nextExprNode = exprNode.get_child(2)\n",
    "                recurse_on_expr(nextExprNode, valNode, pluOrMinusNode)\n",
    "\n",
    "        def recurse(parseNode, astParent):\n",
    "            if parseNode.get_type() == 'Dcl':\n",
    "                children = parseNode.get_children()\n",
    "                astType = children[0].get_type() # floatdcl or intdcl\n",
    "                astVal  = children[1].get_val()  # the id\n",
    "                node = Node(astType, astVal)\n",
    "                self.ast.add_node(node, parent=astParent)\n",
    "                return\n",
    "            \n",
    "            if parseNode.get_type() == 'Stmt':\n",
    "                children = parseNode.get_children()\n",
    "                if children[0].get_type() == 'print':\n",
    "                    astVal  = children[1].get_val() # the id\n",
    "                    node = Node('print', astVal)\n",
    "                    self.ast.add_node(node, parent=astParent)\n",
    "                    return\n",
    "                \n",
    "                if children[1].get_type() == 'assign':\n",
    "                    assignNode = Node('assign')\n",
    "                    self.ast.add_node(assignNode, parent=astParent)\n",
    "\n",
    "                    idNode = children[0]\n",
    "                    self.ast.add_node(idNode, parent=assignNode)\n",
    "\n",
    "                    valNode = children[2].get_child(0)\n",
    "                    \n",
    "                    exprNode = children[3]\n",
    "                    recurse_on_expr(exprNode, valNode, assignNode)\n",
    "                    \n",
    "            for child in parseNode.get_children():\n",
    "                recurse(child, astParent)\n",
    "        \n",
    "        recurse(self.parseTree.get_root(), progNode)\n",
    "\n",
    "    def append_to_call_stack(self, caller):\n",
    "        remainingTokens = ' '.join([tok.type for tok in self.tokens.get_iterable()])\n",
    "        formatted = 2*self.depth*' ' + f'{caller}() --> {remainingTokens}'\n",
    "        self.callStack.append(formatted)\n",
    "\n",
    "    def syntax_error(self, caller):\n",
    "        errorMsg = f'Syntax error in call to {caller}(), here is the stacktrace:\\n\\n'\n",
    "        errorMsg += '\\n'.join(self.callStack)\n",
    "        sys.exit(errorMsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''\n",
    "\n",
    "f b\n",
    "i a\n",
    "a = 5\n",
    "b = a + 3.2\n",
    "p b\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = Scanner(program).scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your program is syntactically valid!\n"
     ]
    }
   ],
   "source": [
    "parser = Parser(tokens)\n",
    "parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prog\n",
       "├── Dcls\n",
       "│   ├── Dcl\n",
       "│   │   ├── floatdcl\n",
       "│   │   └── id (b)\n",
       "│   └── Dcls\n",
       "│       ├── Dcl\n",
       "│       │   ├── intdcl\n",
       "│       │   └── id (a)\n",
       "│       └── Dcls\n",
       "│           └── λ\n",
       "├── Stmts\n",
       "│   ├── Stmt\n",
       "│   │   ├── id (a)\n",
       "│   │   ├── assign\n",
       "│   │   ├── Val\n",
       "│   │   │   └── inum (5)\n",
       "│   │   └── Expr\n",
       "│   │       └── λ\n",
       "│   └── Stmts\n",
       "│       ├── Stmt\n",
       "│       │   ├── id (b)\n",
       "│       │   ├── assign\n",
       "│       │   ├── Val\n",
       "│       │   │   └── id (a)\n",
       "│       │   └── Expr\n",
       "│       │       ├── plus\n",
       "│       │       │   ├── id (a)\n",
       "│       │       │   └── fnum (3.2)\n",
       "│       │       ├── Val\n",
       "│       │       │   └── fnum (3.2)\n",
       "│       │       └── Expr\n",
       "│       │           └── λ\n",
       "│       └── Stmts\n",
       "│           ├── Stmt\n",
       "│           │   ├── print\n",
       "│           │   └── id (b)\n",
       "│           └── Stmts\n",
       "│               └── λ\n",
       "└── $"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_parse_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Program\n",
       "├── floatdcl (b)\n",
       "├── intdcl (a)\n",
       "├── assign\n",
       "│   ├── id (a)\n",
       "│   └── inum (5)\n",
       "├── assign\n",
       "│   ├── id (b)\n",
       "│   └── plus\n",
       "│       ├── id (a)\n",
       "│       └── fnum (3.2)\n",
       "└── print (b)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_ast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextFreeGrammar:\n",
    "    def __init__(self, startSymbol):\n",
    "        self.startSymbol = startSymbol\n",
    "        self.nonterminals = set()\n",
    "        self.terminals = set()\n",
    "        self.productions = set()\n",
    "\n",
    "    ####################################\n",
    "    # Low-level building block methods #\n",
    "    ####################################\n",
    "\n",
    "    def add_production(self, A, rhs):\n",
    "        production = (A, rhs)\n",
    "        self.productions.add(production)\n",
    "\n",
    "        # The rest of this method automatically updates the terminals and\n",
    "        # nonterminals of the grammar; still not sure if we should do this\n",
    "        # here or require the user to call the methods below to register\n",
    "        # these symbols... but for now this is way more convenient\n",
    "        self.add_nonterminal(A)\n",
    "        if A in self.get_terminals():\n",
    "            self.terminals.remove(A)\n",
    "            \n",
    "        for y in rhs:\n",
    "            if y not in self.get_nonterminals():\n",
    "                self.add_terminal(y)\n",
    "        \n",
    "    def add_nonterminal(self, A):\n",
    "        self.nonterminals.add(A)\n",
    "\n",
    "    def add_terminal(self, x):\n",
    "        self.terminals.add(x)\n",
    "\n",
    "    def get_start_symbol(self):\n",
    "        return self.startSymbol\n",
    "\n",
    "    def get_productions(self):\n",
    "        return self.productions\n",
    "\n",
    "    def get_nonterminals(self):\n",
    "        return self.nonterminals\n",
    "    \n",
    "    def get_terminals(self):\n",
    "        return self.terminals\n",
    "    \n",
    "    def is_terminal(self, x):\n",
    "        return x in self.get_terminals()\n",
    "    \n",
    "    def get_lhs(self, p):\n",
    "        return p[0]\n",
    "    def get_rhs(self, p):\n",
    "        return p[1]\n",
    "\n",
    "    def get_productions_for(self, A):\n",
    "        return set(p for p in self.get_productions() if self.get_lhs(p) == A)\n",
    "\n",
    "    def get_occurrences(self, X):\n",
    "        occurrences = set()\n",
    "        for p in self.get_productions():\n",
    "            indicies = [i for i, e in enumerate(self.get_rhs(p)) if e == X]\n",
    "            occurrences |= set((p, i) for i in indicies)\n",
    "        return occurrences\n",
    "\n",
    "    def get_production(self, occurrence):\n",
    "        return occurrence[0]\n",
    "\n",
    "    def get_tail(self, occurrence):\n",
    "        production, index = occurrence\n",
    "        rhs = self.get_rhs(production)\n",
    "        return rhs[index+1:]\n",
    "\n",
    "    ############################\n",
    "    # Methods for CFG analysis #\n",
    "    ############################\n",
    "\n",
    "    def derives_empty_string(self):\n",
    "        symbol_derives_empty = {A:False for A in self.get_nonterminals()}\n",
    "        rule_derives_empty = {}\n",
    "        count = {}\n",
    "        work_list = set()\n",
    "\n",
    "        def check_for_empty(p):\n",
    "            if count[p] == 0:\n",
    "                rule_derives_empty[p] = True\n",
    "                A = self.get_lhs(p)\n",
    "                if not symbol_derives_empty[A]:\n",
    "                    symbol_derives_empty[A] = True\n",
    "                    work_list.add(A)\n",
    "\n",
    "        for p in self.get_productions():\n",
    "            rule_derives_empty[p] = False\n",
    "            count[p] = len(self.get_rhs(p))\n",
    "            check_for_empty(p)\n",
    "\n",
    "        while len(work_list) > 0:\n",
    "            X = work_list.pop()\n",
    "            for x in self.get_occurrences(X):\n",
    "                p = self.get_production(x)\n",
    "                count[p] -= 1\n",
    "                check_for_empty(p)\n",
    "\n",
    "        return symbol_derives_empty, rule_derives_empty\n",
    "\n",
    "    def first(self, nonterminal):\n",
    "        visited_first = {A:False for A in self.get_nonterminals()}\n",
    "\n",
    "        def internal_first(XB):\n",
    "            if len(XB) == 0:\n",
    "                return set()\n",
    "            \n",
    "            first = XB[0]\n",
    "            rest = XB[1:]\n",
    "\n",
    "            if first in self.get_terminals():\n",
    "                return set(first)\n",
    "            \n",
    "            # X is nonterminal\n",
    "            result = set()\n",
    "            if not visited_first[first]:\n",
    "                visited_first[first] = True\n",
    "                for p in self.get_productions_for(first):\n",
    "                    rhs = self.get_rhs(p)\n",
    "                    result |= internal_first(rhs)\n",
    "\n",
    "            symbol_derives_empty, _ = self.derives_empty_string()\n",
    "            if symbol_derives_empty[first]:\n",
    "                result |= internal_first(rest)\n",
    "\n",
    "            return result\n",
    "\n",
    "        return internal_first((nonterminal,))\n",
    "\n",
    "    def follow(self, nonterminal):\n",
    "        visited_follow = {A:False for A in self.get_nonterminals()}\n",
    "\n",
    "        def internal_follow(A):\n",
    "            print(f'internal_follow for A = {A}')\n",
    "            result = set()\n",
    "            if not visited_follow[A]:\n",
    "                for a in self.get_occurrences(A):\n",
    "                    print(f'occurrence a = {a}, tail = {self.get_tail(a)}')\n",
    "                    result |= self.first(self.get_tail(a))\n",
    "                    if all_derives_empty(self.get_tail(a)):\n",
    "                        targ = self.get_lhs(self.get_production(a))\n",
    "                        ans |= internal_follow(targ)\n",
    "            return result\n",
    "        \n",
    "        def all_derives_empty(γ):\n",
    "            for X in γ:\n",
    "                symbol_derives_empty, _ = self.derives_empty_string()\n",
    "                if not symbol_derives_empty[X] or X in self.get_terminals():\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "        return internal_follow(nonterminal)\n",
    "\n",
    "    ################################################\n",
    "    # Methods for printing / string representation #\n",
    "    ################################################\n",
    "\n",
    "    def longest_nonterminal(self):\n",
    "        return max([len(self.get_lhs(p)) for p in self.get_productions()])\n",
    "\n",
    "    def nonterminal_to_string(self, lhs, lhsMaxLen):\n",
    "        string = ''       \n",
    "        thisLhsLen = len(lhs)\n",
    "        numSpaces = lhsMaxLen - thisLhsLen\n",
    "\n",
    "        for i, (_, rhs) in enumerate(self.get_productions_for(lhs)):\n",
    "            if len(rhs) == 0:\n",
    "                rhs = ('λ',)\n",
    "\n",
    "            if i == 0:\n",
    "                string += lhs + numSpaces*' ' +  ' → ' + ' '.join(rhs) + '\\n'\n",
    "            else:\n",
    "                string += (len(lhs) + numSpaces)*' ' +  ' | ' + ' '.join(rhs) + '\\n'\n",
    "\n",
    "        return string\n",
    "\n",
    "    def to_string(self):\n",
    "        length = self.longest_nonterminal()\n",
    "        string = self.nonterminal_to_string(self.startSymbol, length)\n",
    "\n",
    "        for lhs in self.get_nonterminals():\n",
    "            if lhs != self.startSymbol:\n",
    "                string += self.nonterminal_to_string(lhs, length)\n",
    "\n",
    "        return string\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = ContextFreeGrammar('E')\n",
    "\n",
    "cfg.add_production('E',      ('Prefix','(','E',')'))\n",
    "cfg.add_production('E',      ('v','Tail'))\n",
    "cfg.add_production('Prefix', ('f',))\n",
    "cfg.add_production('Prefix', ())\n",
    "cfg.add_production('Tail',   ('+','E'))\n",
    "cfg.add_production('Tail',   ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E      → v Tail\n",
       "       | Prefix ( E )\n",
       "Prefix → f\n",
       "       | λ\n",
       "Tail   → + E\n",
       "       | λ"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "internal_follow for A = Prefix\n",
      "occurrence a = (('E', ('Prefix', '(', 'E', ')')), 0), tail = ('Prefix', '(', 'E', ')')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('Prefix', '(', 'E', ')')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cfg\u001b[38;5;241m.\u001b[39mfollow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrefix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[52], line 155\u001b[0m, in \u001b[0;36mContextFreeGrammar.follow\u001b[0;34m(self, nonterminal)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m internal_follow(nonterminal)\n",
      "Cell \u001b[0;32mIn[52], line 142\u001b[0m, in \u001b[0;36mContextFreeGrammar.follow.<locals>.internal_follow\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_occurrences(A):\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moccurrence a = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, tail = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_tail(a)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 142\u001b[0m     result \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_tail(a))\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_derives_empty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_tail(a)):\n\u001b[1;32m    144\u001b[0m         targ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_lhs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_production(a))\n",
      "Cell \u001b[0;32mIn[52], line 131\u001b[0m, in \u001b[0;36mContextFreeGrammar.first\u001b[0;34m(self, nonterminal)\u001b[0m\n\u001b[1;32m    127\u001b[0m         result \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m internal_first(rest)\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m internal_first((nonterminal,))\n",
      "Cell \u001b[0;32mIn[52], line 119\u001b[0m, in \u001b[0;36mContextFreeGrammar.first.<locals>.internal_first\u001b[0;34m(XB)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# X is nonterminal\u001b[39;00m\n\u001b[1;32m    118\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m visited_first[first]:\n\u001b[1;32m    120\u001b[0m     visited_first[first] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_productions_for(first):\n",
      "\u001b[0;31mKeyError\u001b[0m: ('Prefix', '(', 'E', ')')"
     ]
    }
   ],
   "source": [
    "cfg.follow('Prefix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('Prefix', '(', 'E', ')')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cfg\u001b[38;5;241m.\u001b[39mfirst((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrefix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[52], line 131\u001b[0m, in \u001b[0;36mContextFreeGrammar.first\u001b[0;34m(self, nonterminal)\u001b[0m\n\u001b[1;32m    127\u001b[0m         result \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m internal_first(rest)\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m internal_first((nonterminal,))\n",
      "Cell \u001b[0;32mIn[52], line 119\u001b[0m, in \u001b[0;36mContextFreeGrammar.first.<locals>.internal_first\u001b[0;34m(XB)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# X is nonterminal\u001b[39;00m\n\u001b[1;32m    118\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m visited_first[first]:\n\u001b[1;32m    120\u001b[0m     visited_first[first] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_productions_for(first):\n",
      "\u001b[0;31mKeyError\u001b[0m: ('Prefix', '(', 'E', ')')"
     ]
    }
   ],
   "source": [
    "cfg.first(('Prefix', '(', 'E', ')'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'+'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.first('Tail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = ContextFreeGrammar('S')\n",
    "\n",
    "cfg.add_production('S', ('A','B','c'))\n",
    "cfg.add_production('A', ('a',))\n",
    "cfg.add_production('A', ())\n",
    "cfg.add_production('B', ('b',))\n",
    "cfg.add_production('B', ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b'}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.first('B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = ContextFreeGrammar('Program')\n",
    "cfg.add_production('Program', ('begin','Stmts','end','$'))\n",
    "cfg.add_production('Stmts',   ('Stmt',';','Stmts'))\n",
    "cfg.add_production('Stmts',   ())\n",
    "cfg.add_production('Stmt',    ('simplestmt',))\n",
    "cfg.add_production('Stmt',    ('begin','Stmts','end'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Program → begin Stmts end $\n",
       "Stmts   → Stmt ; Stmts\n",
       "        | λ\n",
       "Stmt    → begin Stmts end\n",
       "        | simplestmt"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = ContextFreeGrammar('A')\n",
    "cfg.add_production('A', ('B','C','D'))\n",
    "cfg.add_production('B', ())\n",
    "cfg.add_production('C', ())\n",
    "cfg.add_production('D', ())\n",
    "cfg.add_production('D', ('Z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': True, 'B': True, 'D': True, 'A': True},\n",
       " {('D', ()): True,\n",
       "  ('A', ('B', 'C', 'D')): True,\n",
       "  ('B', ()): True,\n",
       "  ('D', 'Z'): False,\n",
       "  ('C', ()): True})"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derives_empty_string(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
